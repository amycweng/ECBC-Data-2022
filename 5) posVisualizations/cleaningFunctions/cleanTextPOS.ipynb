{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run parseXMLText() first to get body text an put in new folder then run main with desired folder paths**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to run the cleaning functions separately for each time period and then compile into one folder ('allCleanPeriodsReplaced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1Opium = ['A72549', 'A20501', 'A20900', 'A02366', 'A03456', 'A13300', 'A04785', 'A04936', 'A14882', 'A06400', 'A06401', 'A08175', 'A08904', 'A19026', 'A01410', 'A03123', 'A05054', 'A14595', 'A16466', 'A09920', 'A71324', 'A00611', 'A00991', 'A01227', 'A01228', 'A01231', 'A68254', 'A11333', 'A20928', 'A02364', 'A02495', 'A12777', 'A12778', 'A04556', 'A14485', 'A05237', 'A05312', 'A05569', 'A06607', 'A08239', 'A18047', 'A19165', 'A11406', 'A13314', 'A06108', 'A14032', 'A16845', 'A17654', 'A11909']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2Opium= ['A20069', 'A20811', 'A20836', 'A21106', 'A12609', 'A04425', 'A04680', 'A13820', 'A06143', 'A06903', 'A07083', 'A16884', 'A09800', 'A04780', 'A05102', 'A20901', 'A11347', 'A20583', 'A02440', 'A13646', 'A06182', 'A18935', 'A19740', 'A06820', 'A15599', 'A09713', 'A17464', 'A19029', 'A01443', 'A01444', 'A09144', 'A00419', 'A00777', 'A00888', 'A01017', 'A01194', 'A20619', 'A20620', 'A01256', 'A10464', 'A68944', 'A01818', 'A68403', 'A23464', 'A11395', 'A11899', 'A03189', 'A03244', 'A03512', 'A04640', 'A13821', 'A04852', 'A06190', 'A07217', 'A07267', 'A16522', 'A07834', 'A09198', 'A09202', 'A04602', 'A15794', 'A15834', 'A17230', 'A04632', 'A66951', 'A01822', 'A02362', 'A06927', 'A06950', 'A16851', 'A19018', 'A19403', 'A11350', 'A12656', 'A14264']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "date3Opium = ['A11334', 'B12376', 'B12473', 'A68054', 'A00968', 'A20055', 'A01141', 'A69015', 'A11791', 'A03206', 'A13547', 'A05105', 'A14494', 'A05326', 'A06913', 'A06936', 'A17310', 'A18337', 'A04034', 'A04645', 'A12809', 'A14333', 'A07418', 'A19044']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "date4Opium = ['B16297', 'A69225', 'A11454', 'A11649', 'A11769', 'A13533', 'A04896', 'A14301', 'A14487', 'A14490', 'A14500', 'A05195', 'A14795', 'A15393', 'A15408', 'A07448', 'A16330', 'A08017', 'A08659', 'A09763', 'A00425', 'A19625', 'A00665', 'A10561', 'A03411', 'A04596', 'A13263', 'A13264', 'A08488', 'B01109', 'A68126', 'A03065', 'A14615', 'A71305', 'A71307', 'A68617', 'A16264', 'A10231', 'A11408', 'A01552', 'A01622', 'A02409', 'A02758', 'A06768', 'A06924', 'A17055', 'A08911', 'A08913', 'A15690', 'A09010', 'A16362', 'A16460', 'A01934']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "date5Opium = ['A72143', 'A20093', 'A20507', 'A11474', 'A12135', 'A12245', 'A13217', 'A15848', 'A16622', 'A09208', 'A03066', 'A15137', 'A01446', 'A01454', 'A11278', 'A19070', 'A10508', 'A11176', 'A16628', 'A64906', 'A02327', 'A19160', 'A00291', 'A02060', 'A06304', 'A15684', 'A97168', 'A64772', 'A72146', 'A67746', 'A00695', 'A38409', 'A30077', 'A01052', 'A11527', 'A20863', 'A02520', 'A12817', 'A03752', 'A07248', 'A08637', 'A15139', 'A09011']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "print(len(date5Opium))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrr31/miniconda3/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 0\n",
      "count: 1\n",
      "count: 2\n",
      "count: 3\n",
      "count: 4\n",
      "count: 5\n",
      "count: 6\n",
      "count: 7\n",
      "count: 8\n",
      "count: 9\n",
      "count: 10\n",
      "count: 11\n",
      "count: 12\n",
      "count: 13\n",
      "count: 14\n",
      "count: 15\n",
      "count: 16\n",
      "count: 17\n",
      "count: 18\n",
      "count: 19\n",
      "count: 20\n",
      "count: 21\n",
      "count: 22\n",
      "count: 23\n",
      "count: 24\n",
      "count: 25\n",
      "count: 26\n",
      "count: 27\n",
      "count: 28\n",
      "count: 29\n",
      "count: 30\n",
      "count: 31\n",
      "count: 32\n",
      "count: 33\n",
      "count: 34\n",
      "count: 35\n",
      "count: 36\n",
      "count: 37\n",
      "count: 38\n",
      "count: 39\n",
      "count: 40\n",
      "count: 41\n",
      "count: 42\n",
      "count: 43\n",
      "count: 44\n",
      "count: 45\n",
      "count: 46\n",
      "count: 47\n",
      "count: 48\n",
      "count: 49\n",
      "count: 50\n",
      "count: 51\n",
      "count: 52\n"
     ]
    }
   ],
   "source": [
    "def parseXMLText():\n",
    "    directory='/srv/data/originaldata/relevantEP'\n",
    "    outFolder = '/srv/data/allPeriods/OpiumPOSDate5' #change to path to time period#\n",
    "    c = 0\n",
    "    for file in os.listdir(directory):\n",
    "        path = os.path.join(directory,file)\n",
    "        name = file.split('.')[0]\n",
    "        if name in date5Opium: #change to time period#\n",
    "            f = open(path,'r')\n",
    "            data = f.read()\n",
    "            soup = BeautifulSoup(data,'html.parser')\n",
    "            text_list = []\n",
    "            for sibling in soup.find_all('w'):\n",
    "                parent_name = [parent.name for parent in sibling.parents]\n",
    "                parent_attrs = [parent.attrs for parent in sibling.parents]\n",
    "                divType = [ats['type'] for ats in parent_attrs if 'type' in ats.keys() and ats['type'] == 'coat_of_arms']\n",
    "                divLat = [ats['xml:lang'] for ats in parent_attrs if 'xml:lang' in ats.keys() and ats['xml:lang'] == 'lat']\n",
    "                if not any(x in parent_name for x in ['front', 'table', 'back','foreign']) and 'coat_of_arms' not in divType and 'lat' not in divLat and re.search('lemma',str(sibling)) and str(sibling['lemma']) != 'n/a':\n",
    "                    text_list.append((sibling['lemma'], sibling['pos']))\n",
    "            with open(os.path.join(outFolder, name + '.txt'), 'w+') as outFile:\n",
    "                outFile.write(str(text_list))\n",
    "            f.close()\n",
    "            print(f'count: {c}')\n",
    "            c+=1\n",
    "parseXMLText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTexts(folder):  \n",
    "    textStrings = []\n",
    "    fileNames = []\n",
    "    for file in os.listdir(folder):\n",
    "        fileNames.append(file.split('.')[0])\n",
    "        path = os.path.join(folder,file)\n",
    "        f = open(path,'r')\n",
    "        data = f.read()\n",
    "        textString = ast.literal_eval(data)\n",
    "        textStrings.append(textString)\n",
    "        print('len1',len(textStrings))\n",
    "    return textStrings,fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    stop = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "                \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', \n",
    "                'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \n",
    "                \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "                'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \n",
    "                'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', \n",
    "                'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'or', \n",
    "                'as', 'until', 'while', 'at', 'by', 'for', 'with', 'about', 'between', 'into', \n",
    "                'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', \n",
    "                'down', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n",
    "                'there', 'when', 'whence','where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "                'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n",
    "                'than', 'too', 'very', 's', 't', 'can', 'will', 'don', \"don't\", \"should've\", 'now', \n",
    "                'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", \n",
    "                'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \n",
    "                \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \n",
    "                \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
    "                \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'neve', 'earlier', 'may', \n",
    "                'unto', 'whereof', 'began', 'inasmuch', 'shall', 'de', 'we', 'sir', 'later', 'until', \n",
    "                'could', 'two', 'years', 'mr', 'long', 'till', 'thereof', 'indeed', 'ie', 'himself', \n",
    "                'neither', 'doth', 'thence', 'seem', 'part', 'old', 'definite', 'would', 'iq', \n",
    "                'aforesaid', 'ever', 'might', 'upon', 'how', 'therein', 'through', 'done', 'begin', \n",
    "                'little', 'last', 'also', 'ew', 'etc', 'full', 'second', 'though', 'more', 'his', \n",
    "                'whereas', 'thy', 'thee', 'themselves', 'he', 'why', 'seldom', 'hear', 'what', \n",
    "                'think', 'matter', 'et cetera', 'present', 'do', 'before', 'made', 'there', \n",
    "                'thereforeunto', 'when', 'whilst', 'herself', 'definitely', 'her', 'arrived', \n",
    "                'per', 'afterward', 'far', 'dr', 'saying', 'char', 'whereby', 'or', 'third', \n",
    "                'seems', 'mentioned', 'go', 'esq', 'year', 'likewise', 'must', 'know', 'pag', \n",
    "                'conerning', 'earliest', 'ditto', 'hath', 'without', 'self', 'lib', 'three', \n",
    "                'and', 'itself', 'suchtwo', 'otherwise', 'seeing', 'him', 'latest', 'often', \n",
    "                'cannot', 'et', 'thou', 'est', 'it', 'which', 'can', 'most', 'let', 'almost', \n",
    "                'say', 'late', 'hereby', 'every', 'wherein', 'either', 'much', 'come', 'said', \n",
    "                'else', 'near', 'cap', 'esq', 'viz', 'heard', 'fol', 'like', \n",
    "                'within', 'have', 'thus', 'certainly', 'one', 'make', 'rather', 'she', \n",
    "                'eg', 'where', 'ne', 'since', 'four', 'fourth', 'includes', 'even', 'us', \n",
    "                'gone', 'five', 'anno', 'went', 'thing','according','hove','set',\n",
    "                'ettling', 'hee', 'bee', 'wee', 'mat', 'gen','rom']\n",
    "\n",
    "    cleanedWords = []\n",
    "    for word in text:\n",
    "        dashWord = word[0].replace('-',' ')\n",
    "        newWord = re.sub(r'[^a-zA-Z\\s\\u25CF]','',dashWord.lower())\n",
    "        if not re.search(r\"(\\u25CF)\\1{3,}\", newWord) and len(newWord)>2 and newWord != '' and newWord not in stop:\n",
    "            cleanedWords.append((newWord,word[1]))\n",
    "\n",
    "    return cleanedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTexts(folder):  \n",
    "    textStrings = []\n",
    "    fileNames = []\n",
    "    for file in os.listdir(folder):\n",
    "        if file[0] != '.':\n",
    "            path = os.path.join(folder,file)\n",
    "            f = open(path,'r')\n",
    "            data = f.read()\n",
    "            textString = ast.literal_eval(data)\n",
    "            fileNames.append(file.split('.')[0])\n",
    "            textStrings.append(textString)\n",
    "    print('lenlist',len(textStrings))\n",
    "    return textStrings,fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLemmaDict(path):\n",
    "    with open(path) as f:\n",
    "        data = f.read()\n",
    "    lemmaDict = ast.literal_eval(data)\n",
    "    print(type(lemmaDict))\n",
    "    return lemmaDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMCWDict(path):\n",
    "    with open(path) as f:\n",
    "        data = f.read()\n",
    "    mcwDict = ast.literal_eval(data)\n",
    "    print(type(mcwDict))\n",
    "    return mcwDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceTextLemma(textString,lemmaDict):\n",
    "    #replace lemma words using dictionaries\n",
    "    newWords = []\n",
    "    for word in textString:\n",
    "\n",
    "        found = False\n",
    "        for key,value in zip(list(lemmaDict.keys()), list(lemmaDict.values())):\n",
    "\n",
    "            if word[0] == key:\n",
    "                \n",
    "\n",
    "                newWord = value\n",
    "                newWords.append((newWord,word[1]))\n",
    "                found=True\n",
    "                pass\n",
    "            \n",
    "        if not found:        \n",
    "            newWords.append((word[0],word[1]))\n",
    "    return newWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceTextMCW(textString,mcwDict):\n",
    "    newWords = []\n",
    "    #replace mcw's words using dictionaries\n",
    "    for word in textString:\n",
    "        found = False\n",
    "        for key,value in zip(list(mcwDict.keys()), list(mcwDict.values())):\n",
    "\n",
    "            if word[0] == key:\n",
    "\n",
    "                newWord = value\n",
    "                newWords.append((newWord,word[1]))\n",
    "                found=True\n",
    "                \n",
    "        if not found:\n",
    "            newWord = word[0].replace('\\u25CF','^')\n",
    "            newWords.append((newWord,word[1]))\n",
    "\n",
    "    return newWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(outFolder, name, cleanedText):\n",
    "    with open(os.path.join(outFolder, name + '.txt'), 'w+') as file:\n",
    "            file.write(str(cleanedText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    inFolder = '/srv/data/allPeriods/OpiumPOSDate5' #\n",
    "    outFolder = '/srv/data/allPeriods/OpiumPOSCleanDate5' #\n",
    "\n",
    "    lemmaDict = getLemmaDict('/srv/data/ECBC-Data-2022/stageTwo/lemmas.txt')\n",
    "    mcwDict = getMCWDict('/srv/data/ECBC-Data-2022/stageTwo/dots.txt')\n",
    "    textStrings, fileNames = getTexts(inFolder)\n",
    "    print('len:', len(textStrings))\n",
    "    for name,text in zip(fileNames,textStrings):\n",
    "        cleanedText = cleanText(text)\n",
    "        lemmaList = replaceTextLemma(cleanedText,lemmaDict)\n",
    "        MCWList = replaceTextMCW(lemmaList,mcwDict)\n",
    "\n",
    "        output(outFolder,name,MCWList)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ehr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "601363d1c61e2209eac3ec32d3c1a44dd59f2655f1ede142bd91228995acd555"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
