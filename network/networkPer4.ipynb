{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Social network visualization of the language around tobacco from 1625-1634\n",
    "'''\n",
    "import re\n",
    "import pandas as pd\n",
    "from pyvis.network import Network\n",
    "\n",
    "def authors(csv,search):\n",
    "    '''\n",
    "    Extract text IDs and authors' names.\n",
    "    '''\n",
    "    df = pd.read_csv(csv)\n",
    "    authors = df['author']\n",
    "    ids = df['id']\n",
    "    titles = df['title']\n",
    "    dates = df['date']\n",
    "    count = 0\n",
    "    dict = {}\n",
    "    for idx,TCPID in enumerate(ids):\n",
    "        if TCPID.strip() in search: \n",
    "            words = set(authors[idx].split(';'))\n",
    "            words.discard('')\n",
    "            newWords = []\n",
    "            for w in words: \n",
    "                w = w.strip()\n",
    "                if re.search('printer|engraver',w):continue\n",
    "                newWords.append(w)\n",
    "            dict[TCPID] = [list(set(newWords)),titles[idx],dates[idx]]\n",
    "            count += 1\n",
    "    return dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "'''Get tobacco n-gram features'''\n",
    "inFile = open('/srv/data/periodFeatures/period4features/newtobaccograms.txt','r')\n",
    "inFileLines = inFile.readlines()\n",
    "inFile.close()\n",
    "tobaccoNgrams = {}\n",
    "for line in inFileLines: \n",
    "    line = line.split(':')\n",
    "    features = line[1].strip()\n",
    "    if features == '': continue\n",
    "    tobaccoNgrams[line[0].strip()] = features.strip().split(' ')\n",
    "print(len(tobaccoNgrams))\n",
    "\n",
    "'''Clustering results for tobacco Period 4'''\n",
    "Group0 = ['B12280', 'A10187', 'A03411', 'A19036', 'A68568', 'A11626', 'A14301', 'A14916', 'A15627', 'A09156', 'A00583', 'A19765', 'A20769', 'A12481', 'A13534', 'A14305', 'A08017', 'A09118', 'A08578']\n",
    "Group2 = ['A01055', 'A20065', 'A20356', 'A69225', 'A11151', 'A12155', 'A13520', 'A08977', 'A19012', 'A03559', 'A13948', 'A07024', 'A04633', 'B00490', 'A72399', 'A68252', 'A20075', 'A02827', 'A02836', 'A03807', 'A13415', 'A13436', 'A05320', 'A16489', 'A06692', 'A07025', 'A09242', 'B01146', 'A72254', 'A10402', 'A21075', 'A11153', 'A02909', 'A03240', 'A04658', 'A16924', 'A08690']\n",
    "Group1 = ['A22447', 'A22574', 'A22435', 'A22537', 'A22567', 'A22439', 'A22571']\n",
    "Group3 = ['A02758', 'A06902', 'A16627', 'A01425', 'A03065', 'A05657', 'A11156', 'A01552', 'A06768', 'A01424']\n",
    "Group4 = ['A15685', 'A16507', 'A72911', 'A02325', 'A12471', 'A09010', 'A12458', 'A17595']\n",
    "groups = {0:Group0,1:Group1,2:Group2,3:Group3,4:Group4}\n",
    "groupColors = {0:'pink',1:'purple',2:'darkblue',3:'plum',4:'palevioletred'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''N-gram categorization colors'''\n",
    "from tobaccoGramGroups import plant,recreation,region,medical,trade,commodity,ethics,misc,maleGeneral,female\n",
    "gramGroups = {\n",
    "    'plant':plant,'recreation':recreation,'region':region,'trade':trade,'commodity':commodity,\n",
    "    'ethics':ethics,'misc':misc,'maleGeneral':maleGeneral,'medical':medical,'female':female\n",
    "}\n",
    "edgeColors = {\n",
    "    'plant': '#90C8AC', 'recreation':'#E8D7AD', 'region':'#CCF1FF', 'trade':'#edc7ed','commodity':'#FFD9C0',\n",
    "    'ethics':'#FFCCE1','misc':'lemonchiffon','maleGeneral':'#E0D7FF','medical':'#8C88BA','female':'#BCD2E3'\n",
    "}\n",
    "from itertools import combinations\n",
    "def gramNetwork(gramAuthDict):\n",
    "    '''\n",
    "    Catalogs edges (as well as the edge value, i.e., n-gram) between nodes\n",
    "    Returns a list of tuples (combo,gram) \n",
    "    '''\n",
    "    edgelist = []    \n",
    "    for gram,authList in gramAuthDict.items():\n",
    "        combos = list(combinations(authList,2))\n",
    "        for combo in combos: \n",
    "            # add only edges between DIFFERENT authors. For each different gram, add a new edge  \n",
    "            if combo[1] == combo[0]: continue #avoids edges that point back to self \n",
    "            if ((combo[1],combo[0]),gram) in edgelist: continue\n",
    "            if ((combo[0],combo[1]),gram) in edgelist: continue\n",
    "            edgelist.append((combo,gram))  \n",
    "    return edgelist\n",
    "\n",
    "'''Creates the information that will pop-up when a cursor hovers over a node in the network'''\n",
    "def createTitle(auth,authInfo):\n",
    "    items = ''\n",
    "    for TCPID,gramList in authInfo.items(): \n",
    "        count = 0\n",
    "        for item in gramList: \n",
    "            if count == 0: gramString = f'{item}'\n",
    "            count += 1 \n",
    "            if not count % 2: \n",
    "                if count == len(gramList): gramString += f', {item}'\n",
    "                else: gramString += f', {item},\\n'\n",
    "            elif count>1: gramString += f'\\t{item}'\n",
    "        items += f'{TCPID}: {gramString}\\n'\n",
    "    title = f'{auth}:\\n{items}'\n",
    "    return title\n",
    "    \n",
    "def gramGraph(edgelist,title,authMap,heading,aToGramText):\n",
    "    # Create pyvis graph\n",
    "    g = Network(width=800,height=1000,notebook=True,heading=heading,bgcolor='white',font_color='black',directed=True)\n",
    "    for authPair,gram in edgelist:\n",
    "        if gram=='tobacco_tobacco':continue\n",
    "        a1Color,a2Color = authMap[authPair[0]],authMap[authPair[1]]\n",
    "        \n",
    "        a1Title = createTitle(authPair[0],aToGramText[authPair[0]])\n",
    "        a2Title = createTitle(authPair[1],aToGramText[authPair[1]])\n",
    "\n",
    "        g.add_node(authPair[0], authPair[0], title=a1Title, color=a1Color,labelHighlightBold=True,chosen=True)\n",
    "        g.add_node(authPair[1], authPair[1], title=a2Title, color=a2Color,labelHighlightBold=True,chosen=True)\n",
    "\n",
    "        for groupName,gramList in gramGroups.items():\n",
    "            if gram in gramList:\n",
    "                g.add_edge(authPair[0],authPair[1],title=gram,color=edgeColors[groupName],width=10,arrows='hide')\n",
    "    g.set_edge_smooth('dynamic')\n",
    "    g.repulsion()\n",
    "    g.show(title+\".html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "'''Catalog authors, grams, and TCPIDs'''\n",
    "file = '/srv/data/metadata/tuning/relevant.csv'\n",
    "auths = authors(file,tobaccoNgrams.keys())\n",
    "uniqueAuths = []\n",
    "for TCPID,infoList in auths.copy().items():\n",
    "    uniqueAuths.extend(infoList[0])\n",
    "print(len(set(uniqueAuths)))\n",
    "\n",
    "aToGramText = {}\n",
    "authGrams = {}\n",
    "for TCPID, infoList in auths.items(): \n",
    "    for auth in infoList[0]: \n",
    "        auth = auth.strip(r'\\[').strip(r'\\]')\n",
    "        if auth not in authGrams.keys():\n",
    "            authGrams[auth] = []\n",
    "        authGrams[auth].extend(list(set(tobaccoNgrams[TCPID]))) \n",
    "        if auth not in aToGramText.keys(): \n",
    "            aToGramText[auth] = {TCPID: list(set(tobaccoNgrams[TCPID]))}\n",
    "        else: aToGramText[auth] = aToGramText[auth] | {TCPID: list(set(tobaccoNgrams[TCPID]))}\n",
    "\n",
    "gramToAuths = {}\n",
    "for auth, grams in authGrams.items(): \n",
    "    for gram in grams: \n",
    "        if gram not in gramToAuths.keys(): gramToAuths[gram] = [auth]\n",
    "        else: gramToAuths[gram].append(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "'''Get node colors based on clustering results'''\n",
    "authCluster = {}\n",
    "for TCPID,infoList in auths.items():\n",
    "    for idx,group in enumerate(groups.values()):\n",
    "        if TCPID in group: \n",
    "            for auth in infoList[0]: \n",
    "                if auth not in authCluster.keys(): authCluster[auth] = (idx,1)\n",
    "                else: \n",
    "                    authCluster[auth] = (authCluster[auth][0]+idx, authCluster[auth][1]+1)\n",
    "\n",
    "authMap = {}\n",
    "for auth,nums in authCluster.items():\n",
    "    avg = round(nums[0]/nums[1])\n",
    "    authMap[auth] = groupColors[avg]\n",
    "print(len(authMap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n"
     ]
    }
   ],
   "source": [
    "'''Create and output network'''\n",
    "edges = gramNetwork(gramToAuths)\n",
    "print(len(edges))\n",
    "gramGraph(edges,'Period 4 authors',authMap,'1625-1634 Tobacco N-Gram Author Network',aToGramText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get context windows for n-grams'''\n",
    "import os,re\n",
    "\n",
    "def getTexts(folder,searchList):\n",
    "    fileToText = {}\n",
    "    underscores = {}\n",
    "    for root,dirs,files in os.walk(folder):\n",
    "        for file in files:\n",
    "                if '.txt' not in file: continue\n",
    "                path = os.path.join(folder,file)\n",
    "                f = open(path,'r')\n",
    "                text = f.readlines()[0]\n",
    "                if '_' in file: \n",
    "                        name = file.split('_')[0]\n",
    "                        if name in searchList: \n",
    "                            if name not in underscores.keys(): \n",
    "                                    underscores[name] = text\n",
    "                            else: underscores[name] = underscores[name] + ' ' + text\n",
    "                else: \n",
    "                        name = file.split('.')[0]\n",
    "                        if name in searchList: \n",
    "                            fileToText[name] = text\n",
    "                f.close()\n",
    "        for name,text in underscores.items():\n",
    "            fileToText[name] = text\n",
    "        return fileToText\n",
    "   \n",
    "def context(searchgram,textName):\n",
    "    text = bigramdata[textName]\n",
    "    if (searchgram in text):\n",
    "        indices = [i for i in range(len(text)) if text.startswith(searchgram, i)]\n",
    "        windows = []\n",
    "        for index in indices:\n",
    "            if index > 120: window = text[(index-120):(index+120)].split(' ')\n",
    "            else: window = text[:index+120].split(' ')\n",
    "            del window[0]\n",
    "            del window[-1]\n",
    "            window = ' '.join(window)\n",
    "            windows.append(window)\n",
    "        return windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "'''Map n-grams to TCPIDs'''\n",
    "from tobaccoTexts import per4\n",
    "bigramdata = getTexts('/srv/data/relevantEPBodyNOSTOP', per4)\n",
    "\n",
    "file = '/srv/data/metadata/tuning/relevant.csv'\n",
    "textGrams = {}\n",
    "for TCPID in tobaccoNgrams.keys(): \n",
    "    nGrams = list(set(tobaccoNgrams[TCPID]))\n",
    "    textGrams[TCPID] = []\n",
    "    for gram in nGrams: \n",
    "        gram = re.sub('_',' ',gram)\n",
    "        textGrams[TCPID].append(gram)\n",
    "print(len(textGrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get context windows into a dictionary'''\n",
    "contexts = {}\n",
    "for TCPID,gramList in textGrams.items():\n",
    "    contexts[TCPID] = {}\n",
    "    for gram in gramList: \n",
    "        formatGram = re.sub(' ','_',gram)\n",
    "        contexts[TCPID][formatGram] = context(gram,TCPID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "textToCluster = {}\n",
    "for TCPID in auths.keys(): \n",
    "    for groupIdx, group in groups.items(): \n",
    "        if TCPID in group: textToCluster[TCPID] = groupIdx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Write out documentation for each text in HTML format (ready to be copied and pasted into a HTML doc)'''\n",
    "outfile = open('/srv/data/amy/per4doc.txt','a+')\n",
    "for TCPID, infoList in auths.items(): \n",
    "    outfile.write(f'<b>{TCPID}:</b> Cluster {textToCluster[TCPID]} <ul><li><b>Author: </b> {infoList[0]}</li><li><b>Title: </b> {infoList[1]}</li><li><b>Date: </b> {infoList[2]}</li>')\n",
    "    gramDict = contexts[TCPID]\n",
    "    for gram in gramDict.keys(): \n",
    "        outfile.write(f'<li><b>{gram}</b>')\n",
    "        windows  = gramDict[gram]\n",
    "        for idx,w in enumerate(windows):\n",
    "            if not idx: outfile.write(f'<ul><li>{w}</li></ul>')\n",
    "            else: outfile.write(f'<ul><li>{w}</li></ul>')\n",
    "    outfile.write(f'</ul><br>')\n",
    "outfile.write('\\n\\n\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "163b8b902ef20465a7ecf57c45ba2fc54a366f8c8d80240b381c6f4fa0585aa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
