{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "def model(bodyText,num):\n",
    "    data = [[word for word in simple_preprocess(str(doc))] for doc in bodyText]\n",
    "    id2word = corpora.Dictionary(data)\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in data]\n",
    "    num_topics = num\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                        id2word=id2word,\n",
    "                                        num_topics=num_topics)\n",
    "    for idx, topic in lda_model.show_topics(formatted=False):\n",
    "        return '{}'.format(' '.join([w[0] for w in topic]))\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def topicCloud(topics,title):\n",
    "    topics = ' '.join(topics)\n",
    "    words = topics.split(' ')\n",
    "    word_counts = Counter(words)\n",
    "    print(word_counts.most_common(100))    \n",
    "    word_cloud = WordCloud(background_color = \"white\", width=3000, height=2000, max_words=500, collocations=True).generate_from_frequencies(word_counts)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "folder = '/srv/data/targetCorpusSTOP'\n",
    "outfile = open('/srv/data/targetTopics.txt','a+')\n",
    "missing = ['A23464.txt', 'A12119.txt', 'A10228.txt', 'A11464.txt', 'A11474.txt', 'A08659.txt', 'A16139.txt', 'A22071.txt', 'A00021.txt', 'A12824.txt', 'A22354.txt', 'A13820.txt', 'A12738.txt', 'A22169.txt', 'A17976.txt', 'A16248.txt', 'A19588.txt', 'A02201.txt', 'A03734.txt', 'A06632.txt', 'A15309.txt', 'A06134.txt', 'A59054.txt', 'A35908.txt', 'A68902.txt', 'A21084.txt', 'A01014.txt', 'A19179.txt', 'A15036.txt', 'A06425.txt', 'A14526.txt', 'A07604.txt', 'A18501.txt', 'A19395.txt', 'A69259.txt', 'A01426.txt', 'A70494.txt', 'A14513.txt', 'A68202.txt', 'A14520.txt', 'A01008.txt', 'A22928.txt', 'A03477.txt', 'A13057.txt', 'A03702.txt', 'A08533.txt', 'A13170.txt', 'A17260.txt', 'A22363.txt', 'A05598.txt', 'A00430.txt', 'A01010.txt', 'A22328.txt', 'A11434.txt', 'A22327.txt', 'A14524.txt', 'A05331.txt', 'A11786.txt', 'A01793.txt', 'A06786.txt', 'A16507.txt', 'A78324.txt', 'A10526.txt', 'A04390.txt', 'A67922.txt', 'A01004.txt', 'A11144.txt', 'A20076.txt', 'A14518.txt', 'A19354.txt', 'A34504.txt', 'A19503.txt', 'A13971.txt', 'A05094.txt']\n",
    "count = 0\n",
    "for file in os.listdir(folder):\n",
    "    if file in missing: \n",
    "        count+=1 \n",
    "        if count % 100 == 0: print(count)\n",
    "        topics = []\n",
    "        name = re.findall('\\w{6}',file)[0]\n",
    "        path = os.path.join(folder,file)\n",
    "        f = open(path,'r')\n",
    "        text = f.readlines()\n",
    "        topicWords = model(text,2)\n",
    "        outfile.write(file + ': ' + str(topicWords)+'\\n')\n",
    "        f.close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('take', 343), ('god', 340), ('king', 297), ('good', 289), ('give', 245), ('lord', 180), ('church', 169), ('christ', 140), ('country', 93), ('people', 89), ('prince', 87), ('love', 83), ('ship', 80), ('land', 79), ('find', 78), ('city', 76), ('use', 67), ('sea', 67), ('name', 61), ('pope', 60), ('law', 58), ('town', 57), ('majesty', 57), ('world', 54), ('sin', 53), ('life', 48), ('cause', 46), ('send', 46), ('bishop', 46), ('son', 45), ('john', 44), ('turk', 44), ('emperor', 44), ('death', 42), ('england', 42), ('house', 41), ('kingdom', 41), ('hand', 40), ('christian', 36), ('mean', 36), ('war', 36), ('soul', 34), ('faith', 34), ('captain', 34), ('earl', 32), ('power', 31), ('answer', 31), ('person', 31), ('reason', 30), ('earth', 30), ('holy', 30), ('enemy', 30), ('body', 29), ('true', 28), ('duke', 28), ('army', 28), ('bring', 28), ('company', 27), ('river', 27), ('book', 27), ('soldier', 26), ('master', 26), ('state', 26), ('queen', 26), ('father', 26), ('heart', 25), ('religion', 25), ('knight', 25), ('honour', 24), ('rome', 24), ('parliament', 24), ('henry', 24), ('tell', 23), ('saint', 23), ('english', 23), ('live', 23), ('heaven', 22), ('virtue', 22), ('write', 22), ('water', 22), ('work', 21), ('mind', 21), ('thomas', 21), ('trade', 20), ('speak', 20), ('general', 20), ('arm', 20), ('show', 20), ('fair', 19), ('roman', 19), ('subject', 19), ('plantation', 18), ('hundred', 18), ('lie', 18), ('bear', 18), ('scripture', 18), ('among', 18), ('virginia', 17), ('eye', 17), ('spirit', 16)]\n"
     ]
    }
   ],
   "source": [
    "readFile = open('/srv/data/targetTopics.txt','r')\n",
    "topics = []\n",
    "for line in readFile:\n",
    "    topic = line.split(':')[1].strip()\n",
    "    topics.append(topic)\n",
    "readFile.close()\n",
    "bigString = ' '.join(topics)\n",
    "words = bigString.split(' ')\n",
    "print(Counter(words).most_common(n=100))\n",
    "# topicCloud(topics,'Most Common Topic Words in Target Corpus')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "163b8b902ef20465a7ecf57c45ba2fc54a366f8c8d80240b381c6f4fa0585aa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
