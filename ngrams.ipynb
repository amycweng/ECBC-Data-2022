{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off of work in vocab.ipynb, this program extracts tobacco and drug related bigrams from each text in a given time period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models import Phrases, phrases\n",
    "\n",
    "def getTexts(folder,searchList):\n",
    "    fileToText = {}\n",
    "    underscores = {}\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "                if '.txt' not in file: continue\n",
    "                path = os.path.join(folder,file)\n",
    "                f = open(path,'r')\n",
    "                text = f.readlines()[0]\n",
    "                if '_' in file: \n",
    "                        name = file.split('_')[0]\n",
    "                        if name not in searchList: continue\n",
    "                        if name not in underscores.keys(): \n",
    "                                underscores[name] = text\n",
    "                        else: underscores[name] = underscores[name] + ' ' + text\n",
    "                else: \n",
    "                        name = file.split('.')[0]\n",
    "                        if name not in searchList: continue\n",
    "                        fileToText[name] = text\n",
    "                f.close()\n",
    "        for name,text in underscores.items():\n",
    "            fileToText[name] = text\n",
    "        return fileToText\n",
    "\n",
    "def collectgrams(keylist, searchword, collectlist):\n",
    "        for key in keylist:\n",
    "                if searchword in key.split('_'):\n",
    "                        collectlist.append(key) \n",
    "\n",
    "def getgrams(txt):\n",
    "    infile = open(txt,'r')\n",
    "    lines = infile.readlines()\n",
    "    infile.close()\n",
    "    allgrams = []\n",
    "    for line in lines: \n",
    "        line = line.split(':')\n",
    "        ngrams = line[1].strip()\n",
    "        if '_' in ngrams: \n",
    "                ngrams = ngrams.strip().split(' ')\n",
    "                for n in ngrams:\n",
    "                        allgrams.append(n)\n",
    "        else: continue\n",
    "    return allgrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351\n"
     ]
    }
   ],
   "source": [
    "#change for each time period: index is period - 1\n",
    "period = open('/srv/data/timeranges.txt', 'r').readlines()[3]\n",
    "period = period.strip().strip('[').strip(']').replace(\"'\", '').split(', ')\n",
    "empty = []\n",
    "\n",
    "bigramdata = getTexts('/srv/data/relevantEPBodyNOSTOP', period)\n",
    "bigramtexts = list(bigramdata.values())\n",
    "bigramnames = list(bigramdata.keys())\n",
    "print(len(bigramnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram model trained\n",
      "trigram model trained\n"
     ]
    }
   ],
   "source": [
    "bigrammodel = Phrases(bigramtexts, min_count=2, threshold= 0, scoring='npmi', connector_words=phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "print('bigram model trained')\n",
    "trigrammodel = Phrases(bigrammodel[bigramtexts], min_count=2, threshold= 0, scoring='npmi', connector_words=phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "print('trigram model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 files processed\n",
      "100 files processed\n",
      "150 files processed\n",
      "200 files processed\n",
      "250 files processed\n",
      "300 files processed\n",
      "350 files processed\n",
      "400 files processed\n",
      "450 files processed\n",
      "500 files processed\n"
     ]
    }
   ],
   "source": [
    "#specify tobacco/drugs searchword list:\n",
    "# searchwords = ['tobacco']\n",
    "searchwords = ['opiate', 'opium', 'poppy', 'poppey', 'laudanum']\n",
    "\n",
    "count = 0\n",
    "outfile = open('/srv/data/joy/what.txt', 'w')\n",
    "for text in bigramtexts:\n",
    "    #for outputting to txt file, specify here\n",
    "    name = bigramnames[bigramtexts.index(text)]\n",
    "    testtext = text.strip().split(' ')\n",
    "    grams = []\n",
    "\n",
    "    bgcount = Counter(b for b in bigrammodel[text] if len(b.split(\"_\")) > 1)\n",
    "    tgcount = Counter(t for t in trigrammodel[text] if len(t.split(\"_\")) > 2)\n",
    "   \n",
    "    for searchword in searchwords: \n",
    "        collectgrams(dict(bgcount).keys(), searchword, grams) \n",
    "        collectgrams(dict(tgcount).keys(), searchword, grams)\n",
    "    \n",
    "    gramstring = ' '.join(grams)\n",
    "    outfile.write(name+': '+gramstring+\"\\n\")\n",
    "    count += 1\n",
    "    if count%50 == 0:\n",
    "        print(count, \"files processed\")\n",
    "outfile.close()\n",
    "print('processing complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4tobacco = getgrams('/srv/data/periodFeatures/period4features/newtobaccograms.txt')\n",
    "p1tobacco = getgrams('/srv/data/periodFeatures/period1features/period1tobaccongrams.txt')\n",
    "p2tobacco = getgrams('/srv/data/periodFeatures/period2features/period2tobaccongrams.txt')\n",
    "p3tobacco = getgrams('/srv/data/periodFeatures/period3features/period3tobaccongrams.txt')\n",
    "p5tobacco = getgrams('/srv/data/periodFeatures/period5features/period5tobaccongrams.txt')\n",
    "\n",
    "alltobacco = getgrams('/srv/data/joy/newtobacco.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megalist = p4tobacco + p1tobacco + p2tobacco + p3tobacco + p5tobacco\n",
    "\n",
    "print('uniquely in whole set:', set(alltobacco) - set(megalist))\n",
    "print('uniquely in thirds set:', set(megalist) - set(alltobacco))\n",
    "\n",
    "\n",
    "# check = 'attendance'\n",
    "# for word in p1tobacco:\n",
    "#     if check in word:\n",
    "#         print ('word found in period 1')\n",
    "# for word in p2tobacco:\n",
    "#     if check in word:\n",
    "#         print ('word found in period 2')\n",
    "# for word in p3tobacco:\n",
    "#     if check in word:\n",
    "#         print ('word found in period 3')\n",
    "# for word in p4tobacco:\n",
    "#     if check in word:\n",
    "#         print ('word found in period 4')\n",
    "# for word in p5tobacco:\n",
    "#     if check in word:\n",
    "#         print ('word found in period 5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant = ['call', 'clean', 'common', 'description', 'dry', 'green', 'growth', 'kind', 'leaf', 'manner', 'name', 'part', 'petum', 'piece', 'plant', 'property', 'quality', 'root', 'seed', 'small', 'sophisticate', 'sort', 'strong']\n",
    "medical = ['taste', 'loosen', 'warm', 'hot', 'set', 'almanac', 'cold', 'alymbecke', 'apply', 'bruise', 'suffumigation', 'cane', 'cure', 'draw', 'dress',  'drop', 'head', 'heat', 'help', 'humidity', 'humour', 'infusion', 'oil', 'perfume', 'phlegm', 'powder', 'prepare', 'pudding', 'purge', 'stillify', 'stir',  'vapour', 'water']\n",
    "recreation = ['face', 'arm', 'ash', 'attendance', 'box', 'break', 'breath', 'cast', 'child', 'consume', 'custom', 'cut', 'drawer',  'forget', 'fume', 'glass', 'grant', 'hard', 'have', 'invention', 'keep', 'know', 'leave', 'light', 'make', 'mark', 'paper', 'pipe', 'present', 'rake', 'savour', 'send', 'sit', 'smell', 'smoke', 'stink', 'strew', 'take', 'taker', 'touch', 'unseal', 'use', 'whiff']\n",
    "region = ['brazilian', 'dutch', 'england', 'english', 'foreign', 'indian', 'juice',  'lemnos', 'society', 'sovereign', 'sovereignty', 'spanish', 'trinidada', 'virginia']\n",
    "trade = ['alehouse', 'bag', 'barter', 'bring', 'buy', 'case', 'chest', 'commodity', 'employment', 'furnish', 'gain', 'gift', 'give', 'half', 'house', 'import', 'importation', 'licence', 'line', 'monopoly', 'ounce', 'piece', 'pocket', 'pound', 'quantity', 'retail', 'sell', 'seller', 'ship', 'shop', 'spend', 'store', 'tavern', 'trade', 'trial', 'weight']\n",
    "commodity = ['ale', 'beer', 'butter', 'chandler', 'copper', 'corn', 'cucumber', 'cup', 'drink', 'flax', 'hemlock', 'herb', 'liquorice', 'nightshade', 'other', 'rice', 'sack', 'starch', 'suet', 'sugar', 'sugarcane', 'weed', 'wine']\n",
    "malegen = ['bartholomew', 'boy', 'charles', 'chief', 'doctor', 'farmer', 'gentleman', 'his', 'main', 'maker', 'man', 'our', 'own', 'their', 'they', 'thou', 'thy', 'you', 'your']\n",
    "female = [ 'lady', 'she', 'woman'] \n",
    "moral = ['abuse', 'against', 'bait', 'banish', 'best', 'commend', 'concern', 'counterblaste', 'delectable', 'divine', 'drone', 'entitle', 'exceed', 'excellent', 'famous', 'fast', 'few', 'force', 'good', 'great', 'hurt', 'hurtful', 'ignorant', 'immoderate', 'ingrate', 'lack', 'like', 'little', 'love', 'malady', 'many', 'mighty', 'mistake', 'more', 'much', 'must', 'noble', 'ordinary', 'ought', 'pity', 'poison', 'poor', 'power', 'praise', 'precious', 'profane', 'prove', 'reason', 'require', 'resist', 'respectless', 'right', 'save', 'scarce', 'sin', 'sleight', 'some', 'succour', 'such', 'trick', 'unwholesome', 'virtue', 'vow', 'want', 'well', 'wholesome', 'worse', 'yes']\n",
    "misc = ['far', 'one', 'two', 'about', 'after', 'afterward', 'again', 'all', 'almost', 'also', 'although', 'among', 'any', 'because', 'become', 'before', 'bind', 'both', 'bring', 'but', 'can', 'cause', 'come', 'dru', 'each', 'either', 'engender', 'especial', 'etc', 'even', 'ever', 'fac', 'fill', 'find', 'first', 'fit', 'former', 'forsooth', 'forthwith', 'from', 'here', 'heretofore', 'how', 'if', 'into', 'itself', 'let', 'likewise', 'may', 'mean', 'neither', 'nor', 'not', 'nothing', 'now', 'often', 'once', 'only', 'out', 'ready', 'regard', 'return', 'same', 'say', 'see', 'seem', 'ser', 'shall', 'still', 'sure', 'term', 'than', 'that', 'then', 'there', 'thereby', 'therefore', 'therewith', 'these', 'thing', 'think', 'this', 'those', 'though', 'through', 'till', 'tob', 'too', 'unless', 'upon', 'utter', 'very', 'what', 'whatsoever', 'when', 'where', 'whereas', 'wherein', 'wherewith', 'whether', 'which', 'while', 'who', 'why', 'will', 'within', 'yet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('plant:', sorted(set(plant)))\n",
    "print('medical:', sorted(set(medical)))\n",
    "print('use:', sorted(set(recreation)))\n",
    "print('region:', sorted(set(region)))\n",
    "print('trade:', sorted(set(trade)))\n",
    "print('commodity:', sorted(set(commodity)))\n",
    "print('male/general people:', sorted(set(malegen)))\n",
    "print('female:', sorted(set(female)))\n",
    "print('moral:', sorted(set(moral)))\n",
    "print('misc:', sorted(set(misc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantgrams = []\n",
    "femalegrams = []\n",
    "recreationgrams = []\n",
    "medicalgrams = []\n",
    "regiongrams = []\n",
    "tradegrams = []\n",
    "commoditygrams = []\n",
    "moralgrams = []\n",
    "malegengrams = []\n",
    "miscgrams = []\n",
    "leftover = []\n",
    "\n",
    "for ngram in set(megalist):\n",
    "    for word in ngram.split('_'):\n",
    "        if word in malegen:\n",
    "            malegengrams.append(ngram)\n",
    "            break\n",
    "        if word in female:\n",
    "            femalegrams.append(ngram)\n",
    "        elif word in plant:\n",
    "            plantgrams.append(ngram)\n",
    "            break\n",
    "        elif word in medical:\n",
    "            medicalgrams.append(ngram)\n",
    "        elif word in recreation:\n",
    "            recreationgrams.append(ngram)\n",
    "            break\n",
    "        elif word in region:\n",
    "            regiongrams.append(ngram)\n",
    "            break\n",
    "        elif word in trade:\n",
    "            tradegrams.append(ngram)\n",
    "            break\n",
    "        elif word in commodity:\n",
    "            commoditygrams.append(ngram)\n",
    "            break \n",
    "        elif word in moral:\n",
    "            moralgrams.append(ngram)\n",
    "            break\n",
    "        elif word in misc:\n",
    "            miscgrams.append(ngram)\n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "\n",
    "# print('plant:', plantgrams)\n",
    "# print('use:', usegrams)\n",
    "# print('region:', regiongrams)\n",
    "# print('trade:', tradegrams)\n",
    "# print('commodity:', commoditygrams)\n",
    "# print('moral:', moralgrams)\n",
    "# print('people:', peoplegrams)\n",
    "# print('function:', miscgrams)\n",
    "# print('leftover:', leftover)\n",
    "\n",
    "gramdict = {'plant': plantgrams, 'use': recreationgrams, 'medical': medicalgrams, 'region': regiongrams, 'trade': tradegrams, 'commodity': commoditygrams, 'moral': moralgrams, 'female': femalegrams, 'male/general people': malegengrams, 'misc': miscgrams}\n",
    "# outfile = open('/srv/data/joy/p4groupedtobacco.txt', 'a+')\n",
    "\n",
    "# for key in gramdict:\n",
    "#     outfile.write(key+': '+', '.join(gramdict[key])+\"\\n\")\n",
    "# outfile.close()\n",
    "\n",
    "print(gramdict)\n",
    "\n",
    "# categorised = []\n",
    "# for key in gramdict:\n",
    "#     for word in gramdict[key]:\n",
    "#         categorised.append(word)\n",
    "\n",
    "# leftover = set(megalist) - set(categorised)\n",
    "# print(leftover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictoutfile = open('/srv/data/joy/ngramdict.txt', 'a+')\n",
    "dictoutfile.write('Plant: '+', '.join(set(plantgrams))+\"\\n\")\n",
    "dictoutfile.write('Male/general: '+', '.join(set(malegengrams))+\"\\n\")\n",
    "dictoutfile.write('Female: '+', '.join(set(femalegrams))+\"\\n\")\n",
    "dictoutfile.write('Usage: '+', '.join(set(recreationgrams))+\"\\n\")\n",
    "dictoutfile.write('Medical: '+', '.join(set(medicalgrams))+\"\\n\")\n",
    "dictoutfile.write('Regions: '+', '.join(set(regiongrams))+\"\\n\")\n",
    "dictoutfile.write('Trade: '+', '.join(set(tradegrams))+\"\\n\")\n",
    "dictoutfile.write('Commodity: '+', '.join(set(commoditygrams))+\"\\n\")\n",
    "dictoutfile.write('Ethics: '+', '.join(set(moralgrams))+\"\\n\")\n",
    "dictoutfile.write('Miscellaneous: '+', '.join(set(miscgrams))+\"\\n\")\n",
    "\n",
    "dictoutfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e846d22bd0f16198c95c3cd9e93a943714bae29804f16df7e30c04ce21cb422"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
