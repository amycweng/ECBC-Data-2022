{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re \n",
    "dir = '/srv/data/'\n",
    "\n",
    "'''\n",
    "Retrieve the names of all EEBO-TCP texts \n",
    "'''\n",
    "f1 = 'eebo_phase1_IDs_and_dates.txt'\n",
    "f2 = 'EEBO_Phase2_IDs_and_dates.txt' \n",
    "names = []\n",
    "def getNamesTXT(folder,f):\n",
    "    file = os.path.join(folder,f)\n",
    "    data = open(file,'r')\n",
    "    data = data.readlines()\n",
    "    for d in data:\n",
    "        datum = d.replace('\\n','')\n",
    "        datum = d.split('\\t')\n",
    "        name = datum[0]\n",
    "        names.append(name)\n",
    "\n",
    "getNamesTXT(dir,f1)\n",
    "getNamesTXT(dir,f2)\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/srv/data/eebotcp/texts'\n",
    "'''\n",
    "Retrieves the IDs, i.e., file names, from the current (June 2022) EP library \n",
    "'''\n",
    "epnames = []\n",
    "def getNamesEP(folder):\n",
    "    for f in os.listdir(folder): \n",
    "        name = f.split('.')[0]\n",
    "        if '_' in name:\n",
    "            name = name.split('_')[0]\n",
    "            print(name)\n",
    "        epnames.append(name)\n",
    "\n",
    "for folder in os.listdir(dir):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    local = os.path.join(dir,folder)\n",
    "    getNamesEP(local)\n",
    "    \n",
    "print(len(epnames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Identifies which TCP files are missing from the EP library and \n",
    "then writes those names out into a TXT file\n",
    "'''\n",
    "epmissing = []\n",
    "for n in names:\n",
    "    if n not in epnames:\n",
    "        epmissing.append(n)\n",
    "\n",
    "output = '/srv/data/ECBC-Data-2022/Text_Files/EPmissing.txt'\n",
    "file = open(output,'a+')\n",
    "count = 0\n",
    "for name in epmissing:\n",
    "    count += 1\n",
    "    file.write(name + '\\n')\n",
    "print(count)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions for running stageOne on the TCP files that are missing from the EP library.\n",
    "This is old code that appends each texts' information into a dataframe in memory. \n",
    "Outputs the dataframe as a CSV file after processing the last text.   \n",
    "'''\n",
    "from stageOne import convertTCP,dateTXT\n",
    "import pandas as pd  \n",
    "dates = dateTXT()\n",
    "\n",
    "def getFileNames(file):\n",
    "    phase = open(file,'r')\n",
    "    phase = phase.readlines()\n",
    "    files = []\n",
    "    for entry in phase:\n",
    "        entry = entry.split(' ')\n",
    "        id = entry[0]\n",
    "        fileName = id + '.P4.xml'\n",
    "        files.append(fileName)\n",
    "    return files \n",
    "\n",
    "def convert(files,folder,csv):\n",
    "    count = 0\n",
    "    for f in files:\n",
    "        subfolder = re.findall('\\w{2}',f)[0]\n",
    "        dir = os.path.join(folder,subfolder) \n",
    "        count += 1\n",
    "        if count % 100 == 0 and count != 0:\n",
    "            print(\"Processed \" + str(count) + \" files so far\")\n",
    "        # initalize output CSV dataframe  \n",
    "        if count == 1: \n",
    "            outFile = convertTCP(dir,f,dates)\n",
    "            continue\n",
    "        df = convertTCP(dir,f,dates)\n",
    "        outFile = pd.concat([outFile,df],ignore_index = True)\n",
    "    print('The number of total files is ' + str(count))\n",
    "    outFile.to_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFile = '/srv/data/ECBC-Data-2022/Text_Files/relevantEPmissingPhaseI.txt'\n",
    "IIFile = '/srv/data/ECBC-Data-2022/Text_Files/relevantEPmissingPhaseII.txt'\n",
    "dir1,dir2 = '/srv/data/allPhase1Extract','/srv/data/allPhase2Extract'\n",
    "csvI,csvII = '/srv/data/CSVs/phaseImissing.csv','/srv/data/CSVs/phaseIImissing.csv'\n",
    "filesI, filesII = getFileNames(IFile),getFileNames(IIFile)\n",
    "convert(filesI,dir1,csvI)\n",
    "convert(filesII,dir2,csvII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Identifies which EP texts have multiple parts\n",
    "'''\n",
    "underscores = open('/srv/data/ECBC-Data-2022/Text_Files/EPunderscores.txt','r')\n",
    "relevant = open('/srv/data/ECBC-Data-2022/Text_Files/relevant.txt','r')\n",
    "underscores = underscores.readlines()\n",
    "relevant = relevant.readlines()\n",
    "u = []\n",
    "for id in underscores:\n",
    "    if id in relevant:\n",
    "        id = id.replace('\\n','')\n",
    "        u.append(id)\n",
    "print(len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import keywords\n",
    "'''\n",
    "Filters TCP texts by keywords and date. \n",
    "'''\n",
    "folder = '/srv/data/metadata/TCP metadata/'\n",
    "# output = '/srv/data/metadata/textCounts/virginiaOurTime.txt'\n",
    "# output = '/srv/data/metadata/textCounts/virginiaTCP.txt'\n",
    "# output = '/srv/data/metadata/textCounts/eicOurTime.txt'\n",
    "# output = '/srv/data/metadata/textCounts/eicTCP.txt'\n",
    "# output = '/srv/data/metadata/textCounts/levantOurTime.txt'\n",
    "output = '/srv/data/metadata/textCounts/levantTCP.txt'\n",
    "\n",
    "outFile = open(output,'a+')\n",
    "count = 0\n",
    "for csv in os.listdir(folder):\n",
    "    if '.csv' in csv:\n",
    "        file = os.path.join(folder,csv)\n",
    "        k = keywords(file)\n",
    "        for name in k.keys():\n",
    "            date = re.search('\\d{4}',str(k[name][1]))\n",
    "            if date:\n",
    "                d = date[0]\n",
    "                # for finding texts within a certain timeframe \n",
    "                # if int(d) in range(1580,1640+2):\n",
    "                #     words = k[name][0]\n",
    "                #     for w in words:\n",
    "                #         # if re.search('Virginia|Virginia Company of London',w):\n",
    "                #         # if re.search('East India Company|East Indies',w):\n",
    "                #         if re.search('Turkey|Süleyman|Sultan of the Turks|Mediterranean Sea',w):\n",
    "                #             count += 1 \n",
    "                #             outFile.write(str(name)+' -- '+str(k[name][0])+ ' -- ' +str(d)+ str('\\n'))\n",
    "                #             continue\n",
    "            \n",
    "                # for finding texts in all of TCP \n",
    "                words = k[name][0]\n",
    "                for w in words:\n",
    "                    # if re.search('Virginia|Virginia Company of London',w):\n",
    "                    # if re.search('East India Company|East Indies',w):\n",
    "                    if re.search('Turkey|Süleyman|Sultan of the Turks|Mediterranean Sea',w):\n",
    "                        count += 1 \n",
    "                        outFile.write(str(name)+' -- '+str(k[name][0])+ ' -- ' +str(d)+ str('\\n'))\n",
    "                        continue\n",
    "print('Total count is ' + str(count))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "163b8b902ef20465a7ecf57c45ba2fc54a366f8c8d80240b381c6f4fa0585aa7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
