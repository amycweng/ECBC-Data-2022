{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Unsupervised k-means clustering on plain text file versions of EEBO-TCP texts. \n",
    "The plain text files are generated by running stageOne.py \n",
    "\n",
    "Produces a user-specified number of clusters based on term frequency vectorization. \n",
    "These clusters are described using the keywords found in their corresponding entries \n",
    "in a metadata CSV file also made using stageOne.py \n",
    "\n",
    "The vectorize and cluster functions are adapted from the EarlyPrint Lab: \n",
    "    https://earlyprint.org/jupyterbook/unsupervised.html\n",
    "The pca function is adapted from Ask Python: \n",
    "    https://www.askpython.com/python/examples/plot-k-means-clusters-python \n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict,Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# import our own utility functions \n",
    "from functions import remove_stopwords,getTexts,keywords\n",
    "\n",
    "\n",
    "def vectorize(strings,ids):\n",
    "    # comment below is from EarlyPrint \n",
    "    # sublinear term frequency scaling takes the log of\n",
    "    # term frequencies and can help to de-emphasize function words like pronouns and articles. \n",
    "    tfidf = TfidfVectorizer(min_df=2, sublinear_tf=True)\n",
    "\n",
    "    # Commented out portion below is for removing stopwords \n",
    "    processed = remove_stopwords(strings)\n",
    "    newStrings = []\n",
    "    for doc in processed:\n",
    "        str = ' '.join(doc)\n",
    "        newStrings.append(str)\n",
    "    results = tfidf.fit_transform(newStrings)\n",
    "    \n",
    "    # results = tfidf.fit_transform(strings) #comment this out if you choose to remove stopwords \n",
    "    return pd.DataFrame(results.toarray(), index=ids, columns=tfidf.get_feature_names_out()) # Convert information back to a DataFrame\n",
    "\n",
    "def pca(kmeans,df):\n",
    "    '''\n",
    "    PCA visualization code comes from https://www.askpython.com/python/examples/plot-k-means-clusters-python \n",
    "    '''\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_results = pca.fit_transform(df)\n",
    "    label = kmeans.fit_predict(pca_results)\n",
    "    u_labels = np.unique(label)\n",
    "    for i in u_labels:\n",
    "        plt.scatter(pca_results[label == i , 0] , pca_results[label == i , 1] , label = i)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def cluster(df,ids,num):\n",
    "    # Create a KMeans instance that will look for a specified number of clusters\n",
    "    # Random_state parameter helps for reproducibility. 42 is a common choice \n",
    "    kmeans = KMeans(n_clusters=num, random_state=42) \n",
    "    kmeans.fit(df) \n",
    "    pca(kmeans,df)\n",
    "\n",
    "    kmeans_groups = defaultdict(list)\n",
    "    for k,v in zip(kmeans.labels_,ids):\n",
    "        kmeans_groups[k].append(v)\n",
    "        \n",
    "    for k,v in kmeans_groups.items():\n",
    "        print(k, ': ',v)\n",
    "\n",
    "    return kmeans_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/srv/data/VirginiaEPTextClean'\n",
    "csvFile = '/srv/data/metadata/tuning/virginia.csv'\n",
    "info = getTexts(folder)\n",
    "df = vectorize(info[0],info[1])\n",
    "groups = cluster(df,info[1],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = keywords(csvFile)\n",
    "for k,v in groups.items():\n",
    "    print(f'Group {k}')\n",
    "    keyterms = []\n",
    "    for name in v: \n",
    "        if '_' not in name:\n",
    "            keyterms.extend(words[name][0])\n",
    "    print(Counter(keyterms))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "163b8b902ef20465a7ecf57c45ba2fc54a366f8c8d80240b381c6f4fa0585aa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
