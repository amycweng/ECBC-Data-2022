{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run parseXMLText() first to get body text an put in new folder then run main with desired folder paths**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run replace.ipynb from stage two to replace mcw's and lemmatize :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseXMLText():\n",
    "    directory = '/srv/data/originaldata/relevantEPFiles'\n",
    "    outFolder = '/srv/data/originaldata/relevantEPFilesClean'\n",
    "    c = 0\n",
    "    for file in os.listdir(directory):\n",
    "        path = os.path.join(directory,file)\n",
    "        f = open(path,'r')\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data,'html.parser')\n",
    "        name = file.split('.')[0]\n",
    "        text_list = []\n",
    "        for sibling in soup.find_all('w'):\n",
    "            parent_name = [parent.name for parent in sibling.parents]\n",
    "            parent_attrs = [parent.attrs for parent in sibling.parents]\n",
    "            divType = [ats['type'] for ats in parent_attrs if 'type' in ats.keys() and ats['type'] == 'coat_of_arms']\n",
    "            divLat = [ats['xml:lang'] for ats in parent_attrs if 'xml:lang' in ats.keys() and ats['xml:lang'] == 'lat']\n",
    "            if not any(x in parent_name for x in ['front', 'table', 'back','foreign']) and 'coat_of_arms' not in divType and 'lat' not in divLat and re.search('lemma',str(sibling)) and str(sibling['lemma']) != 'n/a':\n",
    "                text_list.append(sibling['lemma'])\n",
    "        text = ' '.join(text_list)\n",
    "        with open(os.path.join(outFolder, name + '.txt'), 'w+') as outFile:\n",
    "            outFile.write(text)\n",
    "        f.close()\n",
    "        print(f'count: {c}')\n",
    "        c+=1\n",
    "parseXMLText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTexts(folder):\n",
    "    '''\n",
    "    Takes in plain text files and outputs a tuple of lists, with the first being the text\n",
    "    within each file as a string and the second list being the IDs of each text. \n",
    "    '''\n",
    "    textStrings = []\n",
    "    fileNames = []\n",
    "    for file in os.listdir(folder):\n",
    "        path = os.path.join(folder,file)\n",
    "        f = open(path,'r')\n",
    "        text = f.readlines()[0]\n",
    "        textStrings.append(text)\n",
    "        name = file.split('.')[0]\n",
    "        fileNames.append(name)\n",
    "        f.close()\n",
    "    return textStrings,fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    stop = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "                \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', \n",
    "                'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \n",
    "                \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "                'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \n",
    "                'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', \n",
    "                'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'or', \n",
    "                'as', 'until', 'while', 'at', 'by', 'for', 'with', 'about', 'between', 'into', \n",
    "                'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', \n",
    "                'down', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n",
    "                'there', 'when', 'whence','where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "                'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n",
    "                'than', 'too', 'very', 's', 't', 'can', 'will', 'don', \"don't\", \"should've\", 'now', \n",
    "                'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", \n",
    "                'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \n",
    "                \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \n",
    "                \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
    "                \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'neve', 'earlier', 'may', \n",
    "                'unto', 'whereof', 'began', 'inasmuch', 'shall', 'de', 'we', 'sir', 'later', 'until', \n",
    "                'could', 'two', 'years', 'mr', 'long', 'till', 'thereof', 'indeed', 'ie', 'himself', \n",
    "                'neither', 'doth', 'thence', 'seem', 'part', 'old', 'definite', 'would', 'iq', \n",
    "                'aforesaid', 'ever', 'might', 'upon', 'how', 'therein', 'through', 'done', 'begin', \n",
    "                'little', 'last', 'also', 'ew', 'etc', 'full', 'second', 'though', 'more', 'his', \n",
    "                'whereas', 'thy', 'thee', 'themselves', 'he', 'why', 'seldom', 'hear', 'what', \n",
    "                'think', 'matter', 'et cetera', 'present', 'do', 'before', 'made', 'there', \n",
    "                'thereforeunto', 'when', 'whilst', 'herself', 'definitely', 'her', 'arrived', \n",
    "                'per', 'afterward', 'far', 'dr', 'saying', 'char', 'whereby', 'or', 'third', \n",
    "                'seems', 'mentioned', 'go', 'esq', 'year', 'likewise', 'must', 'know', 'pag', \n",
    "                'conerning', 'earliest', 'ditto', 'hath', 'without', 'self', 'lib', 'three', \n",
    "                'and', 'itself', 'suchtwo', 'otherwise', 'seeing', 'him', 'latest', 'often', \n",
    "                'cannot', 'et', 'thou', 'est', 'it', 'which', 'can', 'most', 'let', 'almost', \n",
    "                'say', 'late', 'hereby', 'every', 'wherein', 'either', 'much', 'come', 'said', \n",
    "                'else', 'near', 'cap', 'esq', 'viz', 'heard', 'fol', 'like', \n",
    "                'within', 'have', 'thus', 'certainly', 'one', 'make', 'rather', 'she', \n",
    "                'eg', 'where', 'ne', 'since', 'four', 'fourth', 'includes', 'even', 'us', \n",
    "                'gone', 'five', 'anno', 'went', 'thing','according','hove','set',\n",
    "                'ettling', 'hee', 'bee', 'wee', 'mat', 'gen','rom']\n",
    "\n",
    "    \n",
    "    dashes = text.replace('-',' ')\n",
    "    tokens = [x for x in re.sub(r'[^a-zA-Z\\s\\u25CF]','', dashes.lower()).split(' ') if x != '' and not re.search(r\"(\\u25CF)\\1{3,}\", x) and x if (len(x)>2 or x=='if') and x not in stop]\n",
    "    tokens = ' '.join(tokens)\n",
    "    tokens = ' ' + tokens + ' '\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(outFolder, name, cleanedText):\n",
    "    with open(os.path.join(outFolder, name + '.txt'), 'w+') as file:\n",
    "            file.write(cleanedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 42\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    inFolder = '/srv/data/where'\n",
    "    outFolder = '/srv/data/virginiaCleanest'\n",
    "    textStrings, fileNames = getTexts(inFolder)\n",
    "    print('len:', len(textStrings))\n",
    "    for name,text in zip(fileNames,textStrings):\n",
    "        cleanedText = cleanText(text)\n",
    "        output(outFolder,name,cleanedText)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e846d22bd0f16198c95c3cd9e93a943714bae29804f16df7e30c04ce21cb422"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
