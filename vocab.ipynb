{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/srv/data/ECBC-Data-2022/vocab.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bresearch-datap-ec-01.oit.duke.edu/srv/data/ECBC-Data-2022/vocab.ipynb#ch0000000vscode-remote?line=26'>27</a>\u001b[0m \u001b[39m# normalization turned off\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bresearch-datap-ec-01.oit.duke.edu/srv/data/ECBC-Data-2022/vocab.ipynb#ch0000000vscode-remote?line=27'>28</a>\u001b[0m \u001b[39m# sublinear term frequency scaling turned on (takes log of term frequencies and can help to de-emphasize function words like pronouns and articles.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bresearch-datap-ec-01.oit.duke.edu/srv/data/ECBC-Data-2022/vocab.ipynb#ch0000000vscode-remote?line=28'>29</a>\u001b[0m tfidf \u001b[39m=\u001b[39m TfidfTransformer(norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sublinear_tf\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bresearch-datap-ec-01.oit.duke.edu/srv/data/ECBC-Data-2022/vocab.ipynb#ch0000000vscode-remote?line=29'>30</a>\u001b[0m results \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39;49mfit_transform(df)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bresearch-datap-ec-01.oit.duke.edu/srv/data/ECBC-Data-2022/vocab.ipynb#ch0000000vscode-remote?line=31'>32</a>\u001b[0m readable_results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(results\u001b[39m.\u001b[39mtoarray(), index\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mindex, columns\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bresearch-datap-ec-01.oit.duke.edu/srv/data/ECBC-Data-2022/vocab.ipynb#ch0000000vscode-remote?line=33'>34</a>\u001b[0m \u001b[39m# columns are texts\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bresearch-datap-ec-01.oit.duke.edu/srv/data/ECBC-Data-2022/vocab.ipynb#ch0000000vscode-remote?line=34'>35</a>\u001b[0m \u001b[39m# use .head(30) to show only the top 30 terms\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bresearch-datap-ec-01.oit.duke.edu/srv/data/ECBC-Data-2022/vocab.ipynb#ch0000000vscode-remote?line=35'>36</a>\u001b[0m \u001b[39m# sort using words with highest tfidf scores in A01932 as an example\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1614\u001b[0m, in \u001b[0;36mTfidfTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1596\u001b[0m \u001b[39m\"\"\"Learn the idf vector (global term weights).\u001b[39;00m\n\u001b[1;32m   1597\u001b[0m \n\u001b[1;32m   1598\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1609\u001b[0m \u001b[39m    Fitted transformer.\u001b[39;00m\n\u001b[1;32m   1610\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m \u001b[39m# large sparse data is not supported for 32bit platforms because\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m \u001b[39m# _document_frequency uses np.bincount which works on arrays of\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m \u001b[39m# dtype NPY_INTP which is int32 for 32bit platforms. See #20923\u001b[39;00m\n\u001b[0;32m-> 1614\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1615\u001b[0m     X, accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m), accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m _IS_32BIT\n\u001b[1;32m   1616\u001b[0m )\n\u001b[1;32m   1617\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39missparse(X):\n\u001b[1;32m   1618\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    567\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:665\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    662\u001b[0m                     has_pd_integer_array \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    664\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 665\u001b[0m         dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes_orig)\n\u001b[1;32m    667\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric:\n\u001b[1;32m    668\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dtype_orig\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    669\u001b[0m         \u001b[39m# if input is object, convert to float.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from stopwords import remove_stopwords\n",
    "\n",
    "texts = []\n",
    "textnames = []\n",
    "folder = '/srv/data/dummyText'\n",
    "for file in os.listdir(folder):\n",
    "    path = os.path.join(folder,file)\n",
    "    f = open(path,'r')\n",
    "    data = f.readlines()[0]\n",
    "    texts.append(data)\n",
    "    name = file.split('.')[0]\n",
    "    f.close()\n",
    "\n",
    "tokenized = []\n",
    "for text in texts:\n",
    "    t = remove_stopwords(text)\n",
    "    tokenized.append(t)\n",
    "\n",
    "wordcounts = [Counter(t) for t in tokenized]\n",
    "df = pd.DataFrame(wordcounts, index=[name in textnames]).fillna(0)\n",
    "\n",
    "# normalization turned off\n",
    "# sublinear term frequency scaling turned on (takes log of term frequencies and can help to de-emphasize function words like pronouns and articles.\n",
    "tfidf = TfidfTransformer(norm=None, sublinear_tf=True)\n",
    "results = tfidf.fit_transform(df)\n",
    "\n",
    "readable_results = pd.DataFrame(results.toarray(), index=df.index, columns=df.columns)\n",
    "\n",
    "# columns are texts\n",
    "# use .head(30) to show only the top 30 terms\n",
    "# sort using words with highest tfidf scores in A01932 as an example\n",
    "readable_results.T.sort_values(by=[\"A01932\"], ascending=False).head(30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e846d22bd0f16198c95c3cd9e93a943714bae29804f16df7e30c04ce21cb422"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
