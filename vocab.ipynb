{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import stopwords\n",
    "\n",
    "text = []\n",
    "folder = '/srv/data/texts'\n",
    "for file in os.listdir(folder):\n",
    "    path = os.path.join(folder,file)\n",
    "    f = open(path,'r')\n",
    "    data = f.readlines()[0]\n",
    "    text.append(data)\n",
    "    f.close()\n",
    "\n",
    "tokenized = []\n",
    "counts = []\n",
    "for t in text:\n",
    "    t = stopwords.remove_stopwords(t)\n",
    "    t = t.split(' ')\n",
    "\n",
    "wordcounts = [Counter(token) for token in tokenized]\n",
    "df = pd.DataFrame(counts, index=[f.split(\"/\")[1].split(\".\")[0] for f in files]).fillna(0)\n",
    "\n",
    "# normalization turned off\n",
    "# sublinear term frequency scaling turned on (takes log of term frequencies and can help to de-emphasize function words like pronouns and articles.\n",
    "tfidf = TfidfTransformer(norm=None, sublinear_tf=True)\n",
    "results = tfidf.fit_transform(df)\n",
    "   \n",
    "readable_results = pd.DataFrame(results.toarray(), index=df.index, columns=df.columns)\n",
    "\n",
    "# columns are texts\n",
    "# use .head(30) to show only the top 30 terms\n",
    "# sort using words with highest tfidf scores in A01932 as an example\n",
    "readable_results.T.sort_values(by=[\"A01932\"], ascending=False).head(30)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
