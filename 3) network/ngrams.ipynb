{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off of work in vocab.ipynb, this program extracts tobacco and drug related bigrams from each text in a given time period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models import Phrases, phrases\n",
    "\n",
    "def getTexts(folder,searchList):\n",
    "    fileToText = {}\n",
    "    underscores = {}\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "                if '.txt' not in file: continue\n",
    "                path = os.path.join(folder,file)\n",
    "                f = open(path,'r')\n",
    "                text = f.readlines()[0]\n",
    "                if '_' in file: \n",
    "                        name = file.split('_')[0]\n",
    "                        if name not in searchList: continue\n",
    "                        if name not in underscores.keys(): \n",
    "                                underscores[name] = text\n",
    "                        else: underscores[name] = underscores[name] + ' ' + text\n",
    "                else: \n",
    "                        name = file.split('.')[0]\n",
    "                        if name not in searchList: continue\n",
    "                        fileToText[name] = text\n",
    "                f.close()\n",
    "        for name,text in underscores.items():\n",
    "            fileToText[name] = text\n",
    "        return fileToText\n",
    "\n",
    "def collectgrams(keylist, searchword, collectlist):\n",
    "        for key in keylist:\n",
    "                if searchword in key.split('_'):\n",
    "                        collectlist.append(key) \n",
    "\n",
    "def getgrams(txt):\n",
    "    infile = open(txt,'r')\n",
    "    lines = infile.readlines()\n",
    "    infile.close()\n",
    "    allgrams = []\n",
    "    for line in lines: \n",
    "        line = line.split(':')\n",
    "        ngrams = line[1].strip()\n",
    "        if '_' in ngrams: \n",
    "                ngrams = ngrams.strip().split(' ')\n",
    "                for n in ngrams:\n",
    "                        allgrams.append(n)\n",
    "        else: continue\n",
    "    return allgrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change for each time period: index is period - 1\n",
    "period = open('/srv/data/timeranges.txt', 'r').readlines()[4]\n",
    "period = period.strip().strip('[').strip(']').replace(\"'\", '').split(', ')\n",
    "empty = []\n",
    "\n",
    "bigramdata = getTexts('/srv/data/relevantEPBodyNOSTOP', period)\n",
    "bigramtexts = list(bigramdata.values())\n",
    "bigramnames = list(bigramdata.keys())\n",
    "print(len(bigramnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "for t in bigramtexts:\n",
    "    words = t.split(' ')\n",
    "    training.append(words)\n",
    "\n",
    "print(len(training))\n",
    "bigrammodel = Phrases(training, min_count=2, threshold= 0, scoring='npmi', connector_words=phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "print('bigram model trained')\n",
    "trigrammodel = Phrases(bigrammodel[training], min_count=2, threshold= 0, scoring='npmi', connector_words=phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "print('trigram model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify tobacco/drugs searchword list:\n",
    "# searchwords = ['tobacco']\n",
    "searchwords = ['opiate', 'opium', 'poppy', 'poppey', 'laudanum']\n",
    "\n",
    "count = 0\n",
    "outfile = open('/srv/data/joy/p5opiumngram.txt', 'w')\n",
    "for text in bigramtexts:\n",
    "    #for outputting to txt file, specify here\n",
    "    name = bigramnames[bigramtexts.index(text)]\n",
    "    testtext = text.strip().split(' ')\n",
    "    grams = []\n",
    "\n",
    "    bgcount = Counter(b for b in bigrammodel[testtext] if len(b.split(\"_\")) > 1)\n",
    "    tgcount = Counter(t for t in trigrammodel[testtext] if len(t.split(\"_\")) > 2)\n",
    "   \n",
    "    for searchword in searchwords: \n",
    "        collectgrams(dict(bgcount).keys(), searchword, grams) \n",
    "        collectgrams(dict(tgcount).keys(), searchword, grams)\n",
    "    \n",
    "    gramstring = ' '.join(grams)\n",
    "    outfile.write(name+': '+gramstring+\"\\n\")\n",
    "    count += 1\n",
    "    if count%50 == 0:\n",
    "        print(count, \"files processed\")\n",
    "outfile.close()\n",
    "print('processing complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is useful for retrieving all existing n-grams, checking for thorough categorization of n-grams, as well as printing out each category list for use in social network edge colorings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4tobacco = getgrams('/srv/data/periodFeatures/period4features/newtobaccograms.txt')\n",
    "p1tobacco = getgrams('/srv/data/periodFeatures/period1features/period1tobaccongrams.txt')\n",
    "p2tobacco = getgrams('/srv/data/periodFeatures/period2features/period2tobaccongrams.txt')\n",
    "p3tobacco = getgrams('/srv/data/periodFeatures/period3features/period3tobaccongrams.txt')\n",
    "p5tobacco = getgrams('/srv/data/periodFeatures/period5features/period5tobaccongrams.txt')\n",
    "\n",
    "tobaccos = p1tobacco + p2tobacco + p3tobacco + p4tobacco + p5tobacco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1opium = getgrams('/srv/data/joy/p1opiumngram.txt')\n",
    "p2opium = getgrams('/srv/data/joy/p2opiumngram.txt')\n",
    "p3opium = getgrams('/srv/data/joy/p3opiumngram.txt')\n",
    "p4opium = getgrams('/srv/data/joy/p4opiumngram.txt')\n",
    "p5opium = getgrams('/srv/data/joy/p5opiumngram.txt')\n",
    "\n",
    "drugs = p1opium + p2opium + p3opium + p4opium + p5opium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tobacco\n",
    "# plant = ['call', 'clean', 'common', 'description', 'dry', 'green', 'growth', 'kind', 'leaf', 'manner', 'name', 'part', 'petum', 'piece', 'plant', 'property', 'quality', 'root', 'seed', 'small', 'sophisticate', 'sort', 'strong']\n",
    "# medical = ['taste', 'loosen', 'warm', 'hot', 'set', 'almanac', 'cold', 'alymbecke', 'apply', 'bruise', 'suffumigation', 'cane', 'cure', 'draw', 'dress',  'drop', 'head', 'heat', 'help', 'humidity', 'humour', 'infusion', 'oil', 'perfume', 'phlegm', 'powder', 'prepare', 'pudding', 'purge', 'stillify', 'stir',  'vapour', 'water']\n",
    "# recreation = ['face', 'arm', 'ash', 'attendance', 'box', 'break', 'breath', 'cast', 'child', 'consume', 'custom', 'cut', 'drawer',  'forget', 'fume', 'glass', 'grant', 'hard', 'have', 'invention', 'keep', 'know', 'leave', 'light', 'make', 'mark', 'paper', 'pipe', 'present', 'rake', 'savour', 'send', 'sit', 'smell', 'smoke', 'stink', 'strew', 'take', 'taker', 'touch', 'unseal', 'use', 'whiff']\n",
    "# region = ['brazilian', 'dutch', 'england', 'english', 'foreign', 'indian', 'juice',  'lemnos', 'society', 'sovereign', 'sovereignty', 'spanish', 'trinidada', 'virginia']\n",
    "# trade = ['alehouse', 'bag', 'barter', 'bring', 'buy', 'case', 'chest', 'commodity', 'employment', 'furnish', 'gain', 'gift', 'give', 'half', 'house', 'import', 'importation', 'licence', 'line', 'monopoly', 'ounce', 'piece', 'pocket', 'pound', 'quantity', 'retail', 'sell', 'seller', 'ship', 'shop', 'spend', 'store', 'tavern', 'trade', 'trial', 'weight']\n",
    "# commodity = ['ale', 'beer', 'butter', 'chandler', 'copper', 'corn', 'cucumber', 'cup', 'drink', 'flax', 'hemlock', 'herb', 'liquorice', 'nightshade', 'other', 'rice', 'sack', 'starch', 'suet', 'sugar', 'sugarcane', 'weed', 'wine']\n",
    "# malegen = ['bartholomew', 'boy', 'charles', 'chief', 'doctor', 'farmer', 'gentleman', 'his', 'main', 'maker', 'man', 'our', 'own', 'their', 'they', 'thou', 'thy', 'you', 'your']\n",
    "# female = [ 'lady', 'she', 'woman'] \n",
    "# moral = ['abuse', 'against', 'bait', 'banish', 'best', 'commend', 'concern', 'counterblaste', 'delectable', 'divine', 'drone', 'entitle', 'exceed', 'excellent', 'famous', 'fast', 'few', 'force', 'good', 'great', 'hurt', 'hurtful', 'ignorant', 'immoderate', 'ingrate', 'lack', 'like', 'little', 'love', 'malady', 'many', 'mighty', 'mistake', 'more', 'much', 'must', 'noble', 'ordinary', 'ought', 'pity', 'poison', 'poor', 'power', 'praise', 'precious', 'profane', 'prove', 'reason', 'require', 'resist', 'respectless', 'right', 'save', 'scarce', 'sin', 'sleight', 'some', 'succour', 'such', 'trick', 'unwholesome', 'virtue', 'vow', 'want', 'well', 'wholesome', 'worse', 'yes']\n",
    "# misc = ['far', 'one', 'two', 'about', 'after', 'afterward', 'again', 'all', 'almost', 'also', 'although', 'among', 'any', 'because', 'become', 'before', 'bind', 'both', 'bring', 'but', 'can', 'cause', 'come', 'dru', 'each', 'either', 'engender', 'especial', 'etc', 'even', 'ever', 'fac', 'fill', 'find', 'first', 'fit', 'former', 'forsooth', 'forthwith', 'from', 'here', 'heretofore', 'how', 'if', 'into', 'itself', 'let', 'likewise', 'may', 'mean', 'neither', 'nor', 'not', 'nothing', 'now', 'often', 'once', 'only', 'out', 'ready', 'regard', 'return', 'same', 'say', 'see', 'seem', 'ser', 'shall', 'still', 'sure', 'term', 'than', 'that', 'then', 'there', 'thereby', 'therefore', 'therewith', 'these', 'thing', 'think', 'this', 'those', 'though', 'through', 'till', 'tob', 'too', 'unless', 'upon', 'utter', 'very', 'what', 'whatsoever', 'when', 'where', 'whereas', 'wherein', 'wherewith', 'whether', 'which', 'while', 'who', 'why', 'will', 'within', 'yet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opium\n",
    "plant = ['bear', 'milk', 'big', 'black', 'white', 'long', 'seed', 'corn', 'crown', 'oil', 'red', 'field', 'poppy_opium', 'opium_poppy', 'flower', 'juyce', 'juice', 'leaf', 'garden', 'description', 'root', 'green', 'head', 'wild', 'thorny', 'thornye', 'kind', 'sort', 'tall', 'top', 'resemble', 'name', 'smell', 'leave', 'grow', 'horn', 'cold', 'warm', 'dry', 'sed', 'double', 'wander', 'follow']\n",
    "genuse = ['custom', 'melt', 'use', 'eat', 'portion', 'quantity', 'gather', 'prepare', 'sow', 'take', 'half', 'handful', 'usage', 'serve', 'some', 'have', 'make', 'call', 'say', 'take', 'little', 'confection', 'pure', 'tablet', 'place', 'spatle', 'water', 'cast', 'consist', 'put', 'use', 'ounce', 'perfume', 'cordial', 'form', 'apply', 'anoint', 'grain', 'boil', 'cause', 'inward', 'liquid', 'join', 'camfere', 'earth', 'lay', 'mean', 'swell', 'loch', 'sod', 'equal']\n",
    "medical = ['administer', 'beat', 'castoreum', 'compound', 'decoction', 'dissolve', 'dose', 'drag', 'dram', 'drink', 'dedoction', 'emplaster', 'composition', 'drowsy', 'syrup', 'give', 'tincture', 'paracelsi', 'laudanum_opiate', 'pill', 'thicken', 'diet', 'electuary', 'liquid', 'lozenge', 'medicine', 'extract', 'meconium', 'prepare', 'sleep', 'burn', 'brain']\n",
    "otherplant = ['aloe', 'benzoine', 'benzoin', 'waterlilly', 'mandrake', 'lettuce', 'myrtle', 'rose', 'fig', 'frankincense', 'garlic', 'gum', 'horehound', 'wax', 'benjamin', 'hemlock', 'henbane', 'myrrh', 'violet', 'saffron', 'rosin', 'storax', 'mastic', 'oat', 'quince', 'succory', 'mandragora', 'mandrake', 'sandaraca', 'mallow', 'lettice', 'purslane', 'nightshade', 'ammoniacum', 'houseleek', 'nitre', 'bevercod', 'triphera']\n",
    "region = ['english', 'french', 'cambaia', 'turkey'] \n",
    "maleppl = ['their', 'who', 'you', 'his', 'sir', 'syr', 'spirit']\n",
    "female = ['she']\n",
    "moral = ['against', 'bastard', 'best', 'virtue', 'clean',  'simple', 'deadly', 'scruple', 'much', 'must', 'good', 'than', 'true', 'divinity', 'prickly', 'subordinates', 'more', 'evil', 'well', 'poison', 'frothy', 'crude']\n",
    "misc = ['also', 'any', 'because', 'which', 'there', 'this', 'two', 'when', 'whereof', 'like', 'each', 'even', 'first', 'one', 'foresay', 'without', 'yet', 'that', 'if', 'therein', 'thereof', 'these', 'those', 'three', 'again', 'unto', 'other', 'such', 'then', 'not', 'may', 'twice', 'two', 'according', 'but', 'shall', 'other', 'yet', 'before', 'can', 'every', 'its', 'now', 'than', 'same', 'unto', 'very', 'will', 'therefore', 'lib', 'ana', 'aun']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantgrams = []\n",
    "genusegrams = []\n",
    "medicalgrams = []\n",
    "otherplantgrams = []\n",
    "regiongrams = []\n",
    "malepplgrams = []\n",
    "femalegrams = []\n",
    "moralgrams = []\n",
    "miscgrams = []\n",
    "\n",
    "leftover = []\n",
    "categorised = []\n",
    "for ngram in set(drugs):\n",
    "    for word in ngram.split('_'):\n",
    "        if word in plant:\n",
    "            plantgrams.append(ngram)\n",
    "            categorised.append(ngram)\n",
    "            break\n",
    "        elif word in medical:\n",
    "            medicalgrams.append(ngram)\n",
    "            categorised.append(ngram)\n",
    "            break\n",
    "        elif word in maleppl:\n",
    "            malepplgrams.append(ngram)\n",
    "            categorised.append(ngram)\n",
    "            break\n",
    "        elif word in female:\n",
    "            femalegrams.append(ngram)\n",
    "            categorised.append(ngram)\n",
    "            break\n",
    "        elif word in genuse:\n",
    "            genusegrams.append(ngram)\n",
    "            categorised.append(ngram)\n",
    "            break\n",
    "        elif word in region:\n",
    "            regiongrams.append(ngram)\n",
    "            categorised.append(ngram)\n",
    "            break\n",
    "        elif word in otherplant:\n",
    "            otherplantgrams.append(ngram)\n",
    "            categorised.append(ngram)\n",
    "            break \n",
    "        elif word in moral:\n",
    "            moralgrams.append(ngram)\n",
    "            categorised.append(ngram)\n",
    "            break\n",
    "        elif word in misc:\n",
    "            miscgrams.append(ngram)\n",
    "            categorised.append(ngram)\n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "\n",
    "leftover = set(drugs) - set(categorised)\n",
    "print(leftover)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e846d22bd0f16198c95c3cd9e93a943714bae29804f16df7e30c04ce21cb422"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
